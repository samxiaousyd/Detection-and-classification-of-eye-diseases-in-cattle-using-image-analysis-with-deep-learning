# -*- coding: utf-8 -*-
"""Chapter 6 X-AI

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FhQKoyxAWkTz9gdBRQS45sO2GfwoW_7Z
"""

!pip install tf-keras-vis
!pip install tensorflow pandas numpy matplotlib
!pip install opencv-python-headless

import tensorflow as tf
from tensorflow.keras import layers
import pandas as pd
import numpy as np
import os
import cv2
import matplotlib.pyplot as plt
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    Dense,
    Dropout,
    GlobalAveragePooling2D,
    Input
)
from tensorflow.keras.applications import EfficientNetV2B2
from tensorflow.keras import regularizers
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
from tf_keras_vis.gradcam import GradcamPlusPlus
from tf_keras_vis.utils.model_modifiers import ReplaceToLinear
from tf_keras_vis.utils.scores import CategoricalScore

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Paths to your dataset on Google Drive
csv_path = '/content/drive/My Drive/Deep learning model/Pinkeye/Pinkeye.csv'
image_folder = '/content/drive/My Drive/Deep learning model/Cropped'

# Check if CSV and image folder exist
if not os.path.isfile(csv_path):
    raise FileNotFoundError(f"CSV file not found at {csv_path}")
if not os.path.isdir(image_folder):
    raise FileNotFoundError(f"Image folder not found at {image_folder}")

# Load metadata from CSV file
metadata = pd.read_csv(csv_path)

# Function to load and preprocess images
def load_and_preprocess_image(image_name):
    # Ensure the image_name ends with .JPEG
    if not image_name.endswith('.JPEG'):
        raise ValueError(f"Image name {image_name} does not have the correct .JPEG extension.")

    # Construct the full image path
    path = os.path.join(image_folder, image_name)

    if os.path.isfile(path):
        image = cv2.imread(path)
        if image is not None:
            # Resize the image to 224x224
            image = cv2.resize(image, (224, 224))
            return image
        else:
            print(f"Error: Could not read image {image_name} at {path}")
    else:
        print(f"File '{image_name}' not found in {image_folder}")
    return None

# Check if 'image_id' and 'stage' columns exist
if 'image_id' not in metadata.columns or 'stage' not in metadata.columns:
    raise KeyError("Required columns 'image_id' and 'stage' not found in CSV file.")

# Load images based on the IDs in the CSV
images = [load_and_preprocess_image(row['image_id']) for _, row in metadata.iterrows()]

# Filter out any 'None' entries and keep valid IDs
valid_images = [(img, row['image_id']) for img, (_, row) in zip(images, metadata.iterrows()) if img is not None]
X, valid_image_ids = zip(*valid_images) if valid_images else ([], [])

# Correctly extract target values based on loaded images
y = metadata.loc[metadata['image_id'].isin(valid_image_ids), 'stage'].values

# Convert the feature arrays to NumPy arrays of type float32
X = np.array(X).astype(np.float32)

# Encode the 'stage' labels into numeric values for multiclass classification
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)  # Numeric encoding (e.g., 0, 1, 2, 3)

# One-hot encode the labels
num_classes = len(label_encoder.classes_)  # Number of unique classes (4 for A, R, S, Normal)
y_one_hot = to_categorical(y_encoded, num_classes=num_classes)

# Split data into training, validation, and test sets with stratification
X_train, X_temp, y_train, y_temp = train_test_split(X, y_one_hot, test_size=0.3, random_state=42, stratify=y_encoded)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=2 / 3, random_state=42, stratify=y_temp.argmax(axis=1))

# Verify the dataset shapes
print(f"Shape of X_train: {X_train.shape}, Shape of y_train: {y_train.shape}")
print(f"Shape of X_val: {X_val.shape}, Shape of y_val: {y_val.shape}")
print(f"Shape of X_test: {X_test.shape}, Shape of y_test: {y_test.shape}")
print(f"Class distribution in training set: {np.bincount(y_train.argmax(axis=1))}")
print(f"Class distribution in validation set: {np.bincount(y_val.argmax(axis=1))}")
print(f"Class distribution in test set: {np.bincount(y_test.argmax(axis=1))}")

# Encode the stage column to numeric labels
label_encoder = LabelEncoder()
metadata['stage_encoded'] = label_encoder.fit_transform(metadata['stage'])  # Map classes to integers
num_classes = len(label_encoder.classes_)  # Number of unique classes (4 for A, R, S, Normal)

# One-hot encode the labels for multiclass classification
y = to_categorical(metadata['stage_encoded'], num_classes=num_classes)

# Ensure data consistency
X = np.array(X)  # Assuming X contains the preprocessed images
assert len(X) == len(y), "Mismatch between image data and labels!"

# Split the data into train, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=metadata['stage_encoded']
)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=2/3, random_state=42, stratify=y_temp.argmax(axis=1)  # Use y_temp.argmax for stratification
)

from tensorflow.keras.callbacks import EarlyStopping

!pip install tensorflow==2.12

# Load the EfficientNetV2B2 model
base_model = EfficientNetV2B2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))

# Freeze the base model layers
for layer in base_model.layers:
    layer.trainable = False

# Add custom layers for multiclass classification
x = layers.GlobalAveragePooling2D()(base_model.output)
x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)  # Added L2 regularization
x = layers.Dropout(0.5)(x)
output = layers.Dense(num_classes, activation='softmax')(x)  # Softmax for multiclass classification

# Create and compile the model
model = Model(inputs=base_model.input, outputs=output)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(
    X_train,
    y_train,
    epochs=100,
    batch_size=32,
    validation_data=(X_val, y_val),
    callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]
)

# Evaluate the model
from sklearn.metrics import accuracy_score, classification_report

def evaluate_model(X, y, dataset_name):
    y_pred_probs = model.predict(X)
    y_pred_classes = np.argmax(y_pred_probs, axis=1)
    y_true_classes = np.argmax(y, axis=1)

    accuracy = accuracy_score(y_true_classes, y_pred_classes)
    report = classification_report(y_true_classes, y_pred_classes, target_names=label_encoder.classes_)

    print(f"\nMetrics for {dataset_name}:")
    print(f"Accuracy: {accuracy:.4f}")
    print(report)

    return y_pred_probs, y_pred_classes

# Initialise Grad-CAM++
gradcam = GradcamPlusPlus(model, model_modifier=ReplaceToLinear())

# Find and generate Grad-CAM++ for one correctly classified image per class
def generate_gradcam_per_class(X, y_true, class_names, valid_image_ids):
    """
    Generate Grad-CAM++ heatmaps for one correctly classified training image per class.

    Args:
        X: Training images (numpy array of shape (num_samples, 224, 224, 3)).
        y_true: True class labels (numpy array of shape (num_samples,)).
        class_names: List of class names corresponding to class indices.
        valid_image_ids: List of image IDs corresponding to the training images.
    """
    found_classes = set()  # Keep track of classes we've already processed

    for i in range(len(X)):
        sample_image = X[i]
        true_class = y_true[i]  # True class index

        # Predict the class for the sample image
        sample_pred_prob = model.predict(np.expand_dims(sample_image, axis=0))[0]
        predicted_class = np.argmax(sample_pred_prob)

        # Check if this image is correctly classified and not already processed
        if true_class == predicted_class and true_class not in found_classes:
            found_classes.add(true_class)  # Mark this class as processed
            print(f"Found correctly classified image for class: {class_names[true_class]}")
            print(f"Image ID: {valid_image_ids[i]}")  # Print the image ID for reference

            # Generate Grad-CAM++ heatmap for this image
            score = CategoricalScore(true_class)  # Use the true class for Grad-CAM++
            heatmap = gradcam(score, np.expand_dims(sample_image, axis=0))[0]

            # Plot the heatmap
            plt.imshow(heatmap, cmap='jet')
            plt.axis('off')
            plt.title(f"Grad-CAM++ for {class_names[true_class]}")
            plt.show()

        # Stop once we have found one image for each class
        if len(found_classes) == len(class_names):
            break

# Example Usage
class_names = ['Normal', 'Active', 'R', 'S']  # Update this with the actual order of your classes
y_train_true_classes = np.argmax(y_train, axis=1)  # Convert one-hot labels to class indices

print("Generating Grad-CAM++ heatmaps for one correctly classified image per class...")
generate_gradcam_per_class(X_train, y_train_true_classes, class_names, valid_image_ids)

# Match X_train to their original valid_image_ids
X_array = np.array(X)
X_train_indices = [np.where((X_array == x).all(axis=(1,2,3)))[0][0] for x in X_train]
train_ids = [valid_image_ids[i] for i in X_train_indices]

# Function to overlay heatmap on the original image
def overlay_heatmap_on_image(image, heatmap, alpha=0.6):
    """
    Overlay the heatmap on the original image with adjustable transparency.
    """
    heatmap_resized = cv2.resize(heatmap, (image.shape[1], image.shape[0]))
    heatmap_resized = np.uint8(255 * heatmap_resized)
    heatmap_coloured = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)

    if image.dtype != np.uint8:
        image = np.uint8(image * 255)

    overlayed_image = cv2.addWeighted(image, alpha, heatmap_coloured, 1 - alpha, 0)
    return overlayed_image

# Function to generate Grad-CAM++ heatmaps with overlay
def generate_gradcam_with_overlay(X, y_true, class_names, image_ids):
    """
    Generate Grad-CAM++ overlays for one correctly classified image per class.
    """
    found_classes = set()

    for i in range(len(X)):
        sample_image = X[i]
        true_class = y_true[i]

        sample_pred_prob = model.predict(np.expand_dims(sample_image, axis=0))[0]
        predicted_class = np.argmax(sample_pred_prob)

        if true_class == predicted_class and true_class not in found_classes:
            found_classes.add(true_class)
            print(f"Found correctly classified image for class: {class_names[true_class]}")
            print(f"Image ID: {image_ids[i]}")

            score = CategoricalScore(true_class)
            heatmap = gradcam(score, np.expand_dims(sample_image, axis=0))[0]

            overlayed_image = overlay_heatmap_on_image(sample_image, heatmap)

            plt.figure(figsize=(12, 4))
            plt.subplot(1, 3, 1)
            plt.imshow(sample_image.astype('uint8'))
            plt.axis('off')
            plt.title(f"Original: {class_names[true_class]}")

            plt.subplot(1, 3, 2)
            plt.imshow(heatmap, cmap='jet')
            plt.axis('off')
            plt.title("Heatmap")

            plt.subplot(1, 3, 3)
            plt.imshow(overlayed_image)
            plt.axis('off')
            plt.title("Overlayed")

            plt.show()

        if len(found_classes) == len(class_names):
            break

# Run the Grad-CAM++ visualisation
print("Generating Grad-CAM++ heatmaps with overlays for one correctly classified image per class...")
generate_gradcam_with_overlay(X_train, y_train_true_classes, class_names, train_ids)

pip install lime

from lime import lime_image
from lime.wrappers.scikit_image import SegmentationAlgorithm
import matplotlib.pyplot as plt
import numpy as np
# LIME explainer
explainer = lime_image.LimeImageExplainer()

# Function to explain an image with LIME and generate a heatmap
def explain_with_lime(model, image, class_names, true_label_name, class_index):
    """
    Generate LIME explanations for a specific class in a multiclass classification model.

    Args:
        model: Trained Keras model.
        image: Preprocessed input image (numpy array, shape (224, 224, 3)).
        class_names: List of class names corresponding to model output.
        true_label_name: The true label name for this image (e.g., 'A', 'R', etc.).
        class_index: Index of the class to explain (e.g., 0 for A, 1 for R, etc.).
    """
    # Ensure the image is normalised to [0, 1] for LIME
    image = image / 255.0 if image.max() > 1.0 else image

    # Add batch dimension
    input_image = np.expand_dims(image, axis=0)

    # Define a function for LIME to call the model
    def predict_fn(images):
        return model.predict(images)

    # Define segmentation algorithm for LIME
    segmenter = SegmentationAlgorithm('quickshift', kernel_size=2, max_dist=100, ratio=0.5)

    # Explain the image
    explanation = explainer.explain_instance(
        image,
        predict_fn,
        top_labels=4,
        hide_color=0,
        num_samples=1000,
        segmentation_fn=segmenter
    )

    # Get the mask and heatmap for the target class
    heatmap, mask = explanation.get_image_and_mask(
        label=class_index,
        positive_only=False,  # Include both positive and negative contributions
        hide_rest=False,
        num_features=50  # Increase to 50 features for more coverage
    )

    # Ensure the original image is scaled to [0, 255] for display
    image_display = (image * 255).astype('uint8')

    # Ensure the heatmap is scaled to [0, 255]
    heatmap_display = np.clip(heatmap, 0, 1)  # Clip heatmap to [0, 1]
    heatmap_display = (heatmap_display * 255).astype('uint8')  # Scale to [0, 255]

    # Debug: Check ranges
    print(f"Image range: [{image_display.min()}, {image_display.max()}]")
    print(f"Heatmap range: [{heatmap_display.min()}, {heatmap_display.max()}]")

    # Plot the original image and the heatmap
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(image_display)
    plt.title(f"Original Image: {true_label_name}")
    plt.axis('off')

    plt.subplot(1, 2, 2)
    plt.imshow(heatmap_display, cmap='jet')
    plt.title(f"LIME Heatmap for {class_names[class_index]}")
    plt.axis('off')

    plt.show()

# Function to find and explain one correctly classified image per class
def generate_lime_explanations_by_csv(X, y_true, image_ids, metadata, class_names):
    """
    Generate LIME heatmaps for one correctly classified image per class.

    Args:
        X: Images (numpy array of shape (num_samples, 224, 224, 3)).
        y_true: True class labels (numpy array of shape (num_samples,)).
        image_ids: List of image IDs corresponding to the images.
        metadata: Pandas DataFrame containing the "stage" column for true labels.
        class_names: List of class names corresponding to class indices.
    """
    found_classes = set()

    for i, image_id in enumerate(image_ids):
        sample_image = X[i]

        # Get the true label from the CSV
        true_label_name = metadata.loc[metadata['image_id'] == image_id, 'stage'].values[0]
        true_class = class_names.index(true_label_name)

        # Predict the class for the sample image
        sample_pred_prob = model.predict(np.expand_dims(sample_image, axis=0))[0]
        predicted_class = np.argmax(sample_pred_prob)

        # Check if the image is correctly classified
        if true_class == predicted_class and true_class not in found_classes:
            found_classes.add(true_class)
            print(f"Found correctly classified image for class: {true_label_name}")
            print(f"Image ID: {image_id}")

            # Generate LIME heatmap for this image
            explain_with_lime(
                model,
                sample_image,
                class_names,
                true_label_name=true_label_name,
                class_index=true_class
            )

        # Stop once one correctly classified image for each class is found
        if len(found_classes) == len(class_names):
            break

# Example Usage
class_names = ['Normal', 'A', 'R', 'S']  # Ensure class names are consistent with your CSV
print("Generating LIME heatmaps for one correctly classified image per class...")
generate_lime_explanations_by_csv(X_train, y_train_true_classes, train_ids, metadata, class_names)

# Run this to generate LIME heatmap for IMG ids
target_image_id = 'IMG_1862.JPEG'

# Find the index of the image in your training set
if target_image_id not in train_ids:
    raise ValueError(f"{target_image_id} not found in train_ids.")
index = train_ids.index(target_image_id)

# Get the image and label
sample_image = X_train[index]
true_label_name = metadata.loc[metadata['image_id'] == target_image_id, 'stage'].values[0]
true_class = class_names.index(true_label_name)

# Run LIME explanation
explain_with_lime(
    model,
    sample_image,
    class_names,
    true_label_name=true_label_name,
    class_index=true_class
)

pip install shap

!pip install --upgrade numpy
!pip install shap

!pip uninstall -y numpy
!pip install numpy==1.24.3

import numpy
import shap
print(f"NumPy version: {numpy.__version__}")
print(f"SHAP version: {shap.__version__}")

import numpy as np
import matplotlib.pyplot as plt

# Function to explain an image with SHAP
def explain_with_shap(model, image, class_names, true_label_name, class_index):
    """
    Generate SHAP explanations for a specific class in a multiclass classification model.

    Args:
        model: Trained Keras model.
        image: Preprocessed input image (numpy array, shape (224, 224, 3)).
        class_names: List of class names corresponding to model output.
        true_label_name: The true label name for this image (e.g., 'A', 'R', etc.).
        class_index: Index of the class to explain (e.g., 0 for A, 1 for R, etc.).
    """
    # Ensure the image is scaled to [0, 1] for SHAP's expectations
    if image.max() > 1.0:
        image = image / 255.0  # Convert from [0, 255] to [0, 1]

    # Create a SHAP explainer with Image masker
    masker = shap.maskers.Image("inpaint_telea", image.shape)  # Inpaint missing regions
    explainer = shap.Explainer(model, masker)

    input_image = np.expand_dims(image, axis=0)  # Add batch dimension

    # Generate SHAP values
    shap_values = explainer(input_image)

    # Debug: Print the image and SHAP value ranges
    print(f"Input Image Range: [{image.min()}, {image.max()}]")
    print(f"SHAP Value Range: [{shap_values.values[..., class_index].min()}, {shap_values.values[..., class_index].max()}]")

    # Plot the SHAP heatmap for the specified class
    print(f"Generating SHAP heatmap for class: {class_names[class_index]} ({true_label_name})")
    shap.image_plot(shap_values.values[..., class_index], input_image)

    # Optionally, display the original image separately
    plt.figure(figsize=(6, 6))
    plt.imshow((image * 255).astype('uint8'))
    plt.title(f"Original Image: {true_label_name}")
    plt.axis('off')
    plt.show()

# Function to find and explain one correctly classified image per class
def generate_shap_explanations_by_csv(X, image_ids, metadata, class_names):
    """
    Generate SHAP heatmaps for one correctly classified image per class.

    Args:
        X: Images (numpy array of shape (num_samples, 224, 224, 3)).
        image_ids: List of image IDs corresponding to the images.
        metadata: Pandas DataFrame containing the "stage" column for true labels.
        class_names: List of class names corresponding to class indices.
    """
    found_classes = set()

    for i, image_id in enumerate(image_ids):
        sample_image = X[i]

        # Get the true label from the CSV
        true_label_name = metadata.loc[metadata['image_id'] == image_id, 'stage'].values[0]
        true_class = class_names.index(true_label_name)

        # Predict the class for the sample image
        sample_pred_prob = model.predict(np.expand_dims(sample_image, axis=0))[0]
        predicted_class = np.argmax(sample_pred_prob)

        # Check if the image is correctly classified
        if true_class == predicted_class and true_class not in found_classes:
            found_classes.add(true_class)
            print(f"Found correctly classified image for class: {true_label_name}")
            print(f"Image ID: {image_id}")

            # Generate SHAP heatmap for this image
            explain_with_shap(
                model,
                sample_image,
                class_names,
                true_label_name=true_label_name,
                class_index=true_class
            )

        # Stop once one correctly classified image for each class is found
        if len(found_classes) == len(class_names):
            break

# Example Usage
class_names = ['Normal', 'A', 'R', 'S']  # Ensure class names are consistent with your CSV
print("Generating SHAP heatmaps for one correctly classified image per class...")
generate_shap_explanations_by_csv(X_train, train_ids, metadata, class_names)

# Run this to generate SHAP heatmap for IMG_1862.JPEG
target_image_id = 'IMG_5463.JPEG'

# Find the index of the image in your training set
if target_image_id not in train_ids:
    raise ValueError(f"{target_image_id} not found in train_ids.")
index = train_ids.index(target_image_id)

# Get the image and label
sample_image = X_train[index]
true_label_name = metadata.loc[metadata['image_id'] == target_image_id, 'stage'].values[0]
true_class = class_names.index(true_label_name)

# Run SHAP explanation
explain_with_shap(
    model,
    sample_image,
    class_names,
    true_label_name=true_label_name,
    class_index=true_class
)